{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicate Images & Class Collisions\n",
    "\n",
    "**Authors:**\n",
    "\n",
    "- [Angus Mackenzie](https://github.com/AngusTheMack) ([1106817](mailto:1106817@students.wits.ac.za))\n",
    "- [Nathan Michlo](https://github.com/nmichlo) ([1386161](mailto:1386161@students.wits.ac.za))\n",
    "\n",
    "**Achievement** Detecting which images are duplicates of each other and of those duplicates, which are labeled with differnt classes.\n",
    "\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[92mLOADED\u001b[0m]: \n",
      "[\u001b[95mSTORAGE_DIR\u001b[0m]: \u001b[90m/home/nmichlo/workspace/snake-id-old/notebooks/out\u001b[0m\n",
      "[\u001b[95mDATASET_DIR\u001b[0m]: \u001b[90m/home/nmichlo/downloads/datasets/ssic\u001b[0m\n",
      "[\u001b[95mDATASET_CLASS_CSV\u001b[0m]: \u001b[90m/home/nmichlo/downloads/datasets/ssic/class_idx_mapping.csv\u001b[0m\n",
      "[\u001b[95mDATASET_TRAIN_DIR\u001b[0m]: \u001b[90m/home/nmichlo/downloads/datasets/ssic/train\u001b[0m\n",
      "[\u001b[95mDATASET_TEST_DIR\u001b[0m]: \u001b[90m/home/nmichlo/downloads/datasets/ssic/round1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Utilities\n",
    "import sys\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "# Add root of project to PYTHON_PATH so we can import correctly\n",
    "if os.path.abspath('../') not in {os.path.abspath(path) for path in sys.path}:\n",
    "    sys.path.insert(0, os.path.abspath('../'))\n",
    "    \n",
    "# Import SSIC common stuffs\n",
    "from ssic.ssic import SSIC\n",
    "from ssic.util import set_random_seed, cache_data\n",
    "\n",
    "# if you dont have a .env file set it here\n",
    "os.environ.setdefault('DATASET_DIR', '~/downloads/datasets/ssic')\n",
    "\n",
    "# Initialise SSIC paths, data and other stuffs, searches for a .env file in the project with these variables specified, also checkpoints os.environ and sys.path\n",
    "SSIC.init()\n",
    "\n",
    "def get_info_by_class():\n",
    "    \"\"\" Group image info by classes - returns a dict of lists \"\"\"\n",
    "    # TODO: this should be in SSIC\n",
    "    images_by_class = defaultdict(list)\n",
    "    for name, info in SSIC.get_train_image_info().items():\n",
    "        images_by_class[info['class_id']].append(info)\n",
    "    return dict(images_by_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MD5 Collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[92mLOADED\u001b[0m]: /home/nmichlo/workspace/snake-id-old/notebooks/out/duplicates.json\n",
      "[\u001b[92mLOADED\u001b[0m]: /home/nmichlo/workspace/snake-id-old/notebooks/out/img_info.json\n"
     ]
    }
   ],
   "source": [
    "# TODO: this should be moved into class SSIC\n",
    "\n",
    "def hash_collisions():\n",
    "    from collections import defaultdict\n",
    "    hashes = defaultdict(list)\n",
    "    for info in tqdm(SSIC.get_train_image_info().values()):\n",
    "        md5 = os.popen(f\"md5sum {info['path']}\").read().split(' ')[0]\n",
    "        hashes[md5].append(info['name'])\n",
    "    return dict(hashes)\n",
    "\n",
    "hash_collisions = cache_data(path=os.path.join(SSIC.STORAGE_DIR, 'duplicates.json'), generator=hash_collisions)\n",
    "matching_hashes = {k: v for k, v in hash_collisions.items() if len(v) > 1}\n",
    "\n",
    "img_info = SSIC.get_train_image_info()\n",
    "valid_matching_hashes = {k: [name for name in v if img_info[name]['valid']] for k, v in matching_hashes.items()}\n",
    "valid_matching_hashes = {k: v for k, v in valid_matching_hashes.items() if v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLLISIONS:  1220\n",
      "\u001b[92mVALID COLLISIONS\u001b[0m:  1036\n",
      "\n",
      "UNIQUE COLLISIONS: 515\n",
      "UNIQUE CONFLICTING COLLISIONS: 25\n",
      "UNIQUE VALID COLLISIONS: 514\n",
      "UNIQUE VALID CONFLICTING COLLISIONS: 24\n",
      "\n",
      "\u001b[91mCONFLICTING COLLISIONS\u001b[0m: 232\n",
      "\u001b[91mCONFLICTING VALID COLLISIONS\u001b[0m: 48\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('COLLISIONS: ', sum(len(v) for v in matching_hashes.values()))\n",
    "print('\\033[92mVALID COLLISIONS\\033[0m: ', sum(len(v) for v in valid_matching_hashes.values()))\n",
    "print()\n",
    "\n",
    "conflicting_matching_hashes = {}\n",
    "for key, collisions in matching_hashes.items():\n",
    "    start_id = img_info[collisions[0]]['class_id']\n",
    "    if all(start_id == img_info[c]['class_id'] for c in collisions):\n",
    "        continue\n",
    "    conflicting_matching_hashes[key] = list(collisions)\n",
    "\n",
    "conflicting_valid_matching_hashes = {}\n",
    "for key, collisions in valid_matching_hashes.items():\n",
    "    start_id = img_info[collisions[0]]['class_id']\n",
    "    if all(start_id == img_info[c]['class_id'] for c in collisions):\n",
    "        continue\n",
    "    conflicting_valid_matching_hashes[key] = list(collisions)\n",
    "\n",
    "print(f'UNIQUE COLLISIONS: {len(matching_hashes)}')\n",
    "print(f'UNIQUE CONFLICTING COLLISIONS: {len(conflicting_matching_hashes)}')\n",
    "print(f'UNIQUE VALID COLLISIONS: {len(valid_matching_hashes)}')\n",
    "print(f'UNIQUE VALID CONFLICTING COLLISIONS: {len(conflicting_valid_matching_hashes)}')\n",
    "print()\n",
    "    \n",
    "print('\\033[91mCONFLICTING COLLISIONS\\033[0m:', sum(len(v) for v in conflicting_matching_hashes.values()))\n",
    "print('\\033[91mCONFLICTING VALID COLLISIONS\\033[0m:', sum(len(v) for v in conflicting_valid_matching_hashes.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conflicting Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['84a61a4c635527c06438b75cfa413c9f.jpg', 'a2bd3bc0d0da494b90b080215603373d.jpg'] -> [460, 448]\n",
      "['c2d95843d73fdc7aa4a027d94b5403d6.jpg', 'dc4bb8ad3cbc5ec7cefa49c5f64bb36a.jpg'] -> [639, 635]\n",
      "['dc85f0b6d1b2d87f55687337a9c0c3de.jpg', '254bcaec0e6ce0faa29a19f65fcab453.jpg'] -> [639, 654]\n",
      "['2c73a88777fbff01c2662c3a23fdc573.jpg', '41bf434b469af0fadb39c407b2e1f364.jpg'] -> [639, 654]\n",
      "['a15b8c9fe546a91bf47ce5df88b22ca7.jpg', '7334e90eaa98f966455223a81caddf49.jpg'] -> [639, 697]\n",
      "['74bf306b43c717d51cc234de32dd772c.jpg', '27ea8fbe301561320593737a6cd3af4a.jpg'] -> [394, 872]\n",
      "['e0fc1a5b5866441ba537dd5990c55048.jpg', 'f834f5e0c839ff10f808e796228bd5e1.jpg'] -> [394, 4]\n",
      "['693b99e3c8c9f00a109eac6bce2e00b4.jpg', 'c8bf322e35c32924ddf73fec7f4ff4d8.jpg'] -> [362, 204]\n",
      "['e39e6c80cdc1002d5a4830c92d237d0c.jpg', 'e9580d63e47988d33524129c53d896a4.jpg'] -> [362, 543]\n",
      "['2d13e228b8b52e51553fca64fb7f9986.jpg', 'e8903fdb6110daabcbe1270202a951da.jpg'] -> [362, 543]\n",
      "['6154d719cce4d2ad6cb2dd3f7dbd82b9.jpg', '20dafa2cdd433a8ff45192e4a9f7188d.jpg'] -> [362, 654]\n",
      "['b8301250d849bc53120b182cead139a5.jpg', 'b4b2a99317a0b7e634fc1deb74515f05.jpg'] -> [362, 204]\n",
      "['5e5d8e2f28cae8e295621a9f87d44b54.jpg', '2243ff39ee923500b61248d2483ee943.jpg'] -> [771, 536]\n",
      "['a6737b27438c3e47a25a30e0639270c0.jpg', 'd24278342c0e448d1a2020a6e7dfcc32.jpg'] -> [204, 697]\n",
      "['f6b02c190433d995497a8b236256d28a.jpg', '9a59707253662f930ba36ff9e93c6b01.jpg'] -> [204, 72]\n",
      "['17df9fe3fcce0bc23e8e32aa39200870.jpg', 'ca98f56069b51dff4ff104564bdda8e8.jpg'] -> [204, 697]\n",
      "['13b1e9cc98d8ab7965ec7a9f41a3bd1a.jpg', '5cb7431920522c75f9ee85b77952722d.jpg'] -> [204, 697]\n",
      "['1b1a423e0674d8b7ff30a79c791cce53.jpg', 'd40d96baf78047580482013a3938298b.jpg'] -> [204, 654]\n",
      "['be8d4395df703d17df251038eb5fc4d2.jpg', '48a21566e2d44e55d417fa5a3e4d9dd0.jpg'] -> [697, 654]\n",
      "['e5fd21b7ee74702c0802390b1cccc9d0.jpg', '884af87e133ab4479ff67b2c8df753a3.jpg'] -> [697, 72]\n",
      "['1cfbbb51f7d3d56bba577f93104162fe.jpg', 'a76f20a85bdb3f3a7ec9f855ab8dae6b.jpg'] -> [697, 72]\n",
      "['2e9b1118cf5dde160ac2c1c8b38b0008.jpg', '1005f1e416c0b145fc7e3e83a6b083c1.jpg'] -> [966, 540]\n",
      "['5f361dd7261f5e9b275eaa0c50f0ce21.jpg', '62bd8caab77ecc3b0b379530e6a08829.jpg'] -> [543, 72]\n",
      "['4d037690211230db633d0f47dbf139e9.jpg', 'b7d30778c91bac2b67b0a56825d7acd0.jpg'] -> [450, 128]\n"
     ]
    }
   ],
   "source": [
    "# THESE MD5 COLLISIONS HAVE CONFLICTING CLASSES\n",
    "for collisions in conflicting_matching_hashes.values():\n",
    "    print(collisions, '->', [img_info[name]['class_id'] for name in collisions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81871\n",
      "81871\n"
     ]
    }
   ],
   "source": [
    "image_names = set(SSIC.get_train_image_info())\n",
    "valid_image_names = set(name for name, info in SSIC.get_train_image_info().items() if info['valid'])\n",
    "\n",
    "duplicate_names                   = set(name for names in matching_hashes.values() for name in sorted(names))\n",
    "valid_duplicate_names             = set(name for names in valid_matching_hashes.values() for name in sorted(names))\n",
    "conflicting_duplicate_names = set(name for names in conflicting_matching_hashes.values() for name in sorted(names))\n",
    "conflicting_valid_duplicate_names = set(name for names in conflicting_valid_matching_hashes.values() for name in sorted(names))\n",
    "\n",
    "kept_duplicate_names                   = set(sorted(names)[0] for names in matching_hashes.values())\n",
    "kept_valid_duplicate_names             = set(sorted(names)[0] for names in valid_matching_hashes.values())\n",
    "\n",
    "# Using invalid\n",
    "kept = image_names\n",
    "kept -= (duplicate_names - kept_duplicate_names)\n",
    "kept -= conflicting_duplicate_names\n",
    "print(len(kept))\n",
    "kept_a = tuple(sorted(kept))\n",
    "\n",
    "# Using valid - should match\n",
    "kept = valid_image_names\n",
    "kept -= (valid_duplicate_names - kept_valid_duplicate_names)\n",
    "kept -= conflicting_valid_duplicate_names\n",
    "print(len(kept))\n",
    "kept_b = tuple(sorted(kept))\n",
    "\n",
    "assert kept_a == kept_b\n",
    "del kept_a\n",
    "del kept_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class:\t\torig|kept\n",
      "-------------------------\n",
      "class-784:\t517 | 507\n",
      "class-629:\t527 | 521\n",
      "class-561:\t531 | 529\n",
      "class-273:\t583 | 580\n",
      "class-734:\t593 | 591\n",
      "class-957:\t605 | 597\n",
      "class-526:\t629 | 610\n",
      "class-326:\t639 | 631\n",
      "class-239:\t677 | 673\n",
      "class-653:\t715 | 704\n",
      "class-128:\t749 | 744\n",
      "class-72:\t852 | 833\n",
      "class-1059:\t890 | 888\n",
      "class-811:\t910 | 906\n",
      "class-663:\t961 | 951\n",
      "class-450:\t1003 | 991\n",
      "class-597:\t1006 | 1001\n",
      "class-540:\t1053 | 1051\n",
      "class-654:\t1071 | 1061\n",
      "class-857:\t1138 | 1121\n",
      "class-707:\t1148 | 1146\n",
      "class-635:\t1186 | 1177\n",
      "class-394:\t1232 | 1228\n",
      "class-536:\t1368 | 1353\n",
      "class-543:\t1383 | 1343\n",
      "class-460:\t1394 | 1380\n",
      "class-966:\t1471 | 1462\n",
      "class-140:\t1498 | 1493\n",
      "class-4:\t1500 | 1490\n",
      "class-1625:\t1677 | 1672\n",
      "class-854:\t1773 | 1767\n",
      "class-581:\t1908 | 1891\n",
      "class-508:\t2068 | 2055\n",
      "class-78:\t2149 | 2125\n",
      "class-362:\t2154 | 2105\n",
      "class-639:\t2183 | 2171\n",
      "class-390:\t2295 | 2290\n",
      "class-804:\t2555 | 2543\n",
      "class-448:\t2565 | 2539\n",
      "class-67:\t3201 | 3187\n",
      "class-337:\t3472 | 3463\n",
      "class-697:\t4619 | 4572\n",
      "class-872:\t5525 | 5473\n",
      "class-771:\t5536 | 5479\n",
      "class-204:\t11092 | 10977\n",
      "-------------------------\n",
      "kept: 507 10977 1819.3555555555556 1821.0818537409818 1228.0\n",
      "orig: 517 11092 1835.5777777777778 1838.9425643727236 1232.0\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "image_info = SSIC.get_train_image_info()\n",
    "\n",
    "classes_kept = defaultdict(list)\n",
    "for name in kept:\n",
    "    classes_kept[image_info[name]['class_id']].append(name)\n",
    "classes = defaultdict(list)\n",
    "for name in image_info:\n",
    "    classes[image_info[name]['class_id']].append(name)\n",
    "\n",
    "class_kept_counts = {k: len(v) for k, v in classes_kept.items()}\n",
    "class_counts = {k: len(v) for k, v in classes.items()}\n",
    "\n",
    "print('class:\\t\\torig|kept\\n-------------------------')\n",
    "for k in sorted(class_counts, key=class_counts.__getitem__):\n",
    "    print(f'class-{k}:\\t{class_counts[k]} | {class_kept_counts[k]}')\n",
    "\n",
    "    \n",
    "counts_kept = list(class_kept_counts.values())\n",
    "counts = list(class_counts.values())\n",
    "\n",
    "print('-------------------------')\n",
    "print('kept:', np.min(counts_kept), np.max(counts_kept), np.mean(counts_kept), np.std(counts_kept), np.median(counts_kept))\n",
    "print('orig:', np.min(counts), np.max(counts), np.mean(counts), np.std(counts), np.median(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "print(len(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
