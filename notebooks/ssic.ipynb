{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snake Species Identification Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Authors**:\n",
    "- Angus Mackenzie (1106817)\n",
    "- Nathan Michlo (1386161)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pprint import pprint\n",
    "\n",
    "import dotenv\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add Local Modules to `PYTHON_PATH`**\n",
    "- This assumes that jupyter server was launched from the `root` directory of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE ORIGINAL sys.path AND RESTORE\n",
    "def restore_sys_path():\n",
    "    global _ORIG_SYS_PATH\n",
    "    if '_ORIG_SYS_PATH' not in globals():\n",
    "        _ORIG_SYS_PATH = list(sys.path) # shallow copy\n",
    "    sys.path = list(_ORIG_SYS_PATH)     # shallow copy\n",
    "\n",
    "# APPEND TO sys.path\n",
    "def add_python_path(path):\n",
    "    sys.path.insert(0, os.path.abspath(path))\n",
    "    \n",
    "# Methods to visualise CNN activations: https://github.com/utkuozbulak/pytorch-cnn-visualizations\n",
    "add_python_path('vendor/pytorch-cnn-visualizations')\n",
    "# Mish activation function: https://github.com/digantamisra98/Mish\n",
    "add_python_path('vendor/Mish')\n",
    "# Variance of the Adaptive Learning Rate: https://github.com/LiyuanLucasLiu/RAdam\n",
    "add_python_path('vendor/RAdam')\n",
    "# Lookahead optimizer: https://github.com/alphadl/lookahead.pytorch\n",
    "add_python_path('vendor/lookahead.pytorch')\n",
    "# Ranger=RAdam+Lookahead: https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer\n",
    "add_python_path('vendor/Ranger-Deep-Learning-Optimizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "File that stores environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOADED]: /home/nmichlo/downloads/tmp/snake-id/.env\n"
     ]
    }
   ],
   "source": [
    "if dotenv.load_dotenv(dotenv.find_dotenv()):\n",
    "    print(f'[LOADED]: {dotenv.find_dotenv()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DATASET LOCATION]: /home/nmichlo/downloads/datasets/ssic\n"
     ]
    }
   ],
   "source": [
    "# pretty much only need to change DATASET_DIR\n",
    "DATASET_DIR          = os.environ.get('DATASET_DIR', 'data')\n",
    "print(f'[DATASET LOCATION]: {DATASET_DIR}')\n",
    "\n",
    "DATASET_SSIC_CLASSES = os.environ.get('DATASET_SSIC_CLASSES', os.path.join(DATASET_DIR, 'class_idx_mapping.csv'))\n",
    "DATASET_SSIC_TRAIN   = os.environ.get('DATASET_SSIC_TRAIN', os.path.join(DATASET_DIR, 'train'))\n",
    "DATASET_SSIC_TEST    = os.environ.get('DATASET_SSIC_TEST', os.path.join(DATASET_DIR, 'round1'))\n",
    "OUTPUT_FOLDER        = os.environ.get('OUTPUT_FOLDER', 'out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str -> int\n",
    "NAME_CLASS_MAP = {name: cls for (name, cls) in pd.read_csv(DATASET_SSIC_CLASSES).values}\n",
    "# int -> str\n",
    "CLASS_NAME_MAP = {cls: name for (name, cls) in NAME_CLASS_MAP.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_img_paths(validate=True):\n",
    "    \"\"\"\n",
    "    Get all the paths of training images, verifying that images of any paths returned are actually valid.\n",
    "    \"\"\"\n",
    "    img_paths_valid, img_paths_invalid = [], []\n",
    "    # LOOP THROUGH CLASS FOLDERS\n",
    "    for cls_name in tqdm(os.listdir(DATASET_SSIC_TRAIN)):\n",
    "        cls_path = os.path.join(DATASET_SSIC_TRAIN, cls_name)\n",
    "        # LOOP THROUGH CLASS IMAGES (IN CLASS FOLDER)\n",
    "        for img_name in os.listdir(cls_path):\n",
    "            img_path = os.path.join(cls_path, img_name)\n",
    "            data = (img_path, int(cls_name[len('class-'):]))\n",
    "            try:\n",
    "                if validate:\n",
    "                    img = Image.open(img_path)\n",
    "                    img.verify()\n",
    "                img_paths_valid.append(data)\n",
    "            except (IOError, SyntaxError) as e:\n",
    "                img_paths_invalid.append(data)\n",
    "    if validate:\n",
    "        return img_paths_valid, img_paths_invalid\n",
    "    else:\n",
    "        assert not img_paths_invalid\n",
    "        return img_paths_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:30<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#valid images:   82417\n",
      "#invalid images: 184\n",
      "All 45 classes are present in data!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# tuples of (path, class_id)\n",
    "VALID_IMG_PATHS_CLASS, INVALID_IMG_PATHS_CLASS = get_train_img_paths(validate=True)\n",
    "\n",
    "print(f'#valid images:   {len(VALID_IMG_PATHS_CLASS)}')\n",
    "print(f'#invalid images: {len(INVALID_IMG_PATHS_CLASS)}')\n",
    "\n",
    "# Make sure that all classes appear in data and vice versa\n",
    "assert len({class_id for path, class_id in VALID_IMG_PATHS} - set(CLASS_NAME_MAP)) == 0\n",
    "assert len(set(CLASS_NAME_MAP) - {class_id for path, class_id in VALID_IMG_PATHS}) == 0\n",
    "\n",
    "print(f'All {len(CLASS_NAME_MAP)} classes are present in data!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source article: https://medium.com/@Stormblessed/2460292bcfb\n",
    "# annotated data: https://drive.google.com/uc?id=18dx_5Ngmc56fDRZ6YZA_elX-0ehtV5U6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile = urllib.URLopener().retrieve('https://drive.google.com/uc?id=18dx_5Ngmc56fDRZ6YZA_elX-0ehtV5U6', f'{DATASET_DIR}/annotations.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
